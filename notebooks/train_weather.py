# import os
# import time
# import json
# import torch
# from torch import nn
# from torchvision import datasets, transforms, models
# from torch.utils.data import DataLoader
# from sklearn.metrics import confusion_matrix
# from tqdm import tqdm

# # –ü—É—Ç–∏
# DATA_PATH = r"C:\Users\safar\OneDrive\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\elbrus\my_project_2_1\data\weather"
# SAVE_PATH = "models/resnet_weather.pt"
# LOG_PATH = "models/train_log.json"
# CONFUSION_PATH = "models/confusion.json"
# EPOCHS = 3
# BATCH_SIZE = 16

# # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize([0.485, 0.456, 0.406],
#                          [0.229, 0.224, 0.225])
# ])

# # –î–∞—Ç–∞—Å–µ—Ç –∏ DataLoader
# dataset = datasets.ImageFolder(DATA_PATH, transform=transform)
# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
# classes = dataset.classes
# print("–ö–ª–∞—Å—Å—ã:", classes)

# # –ú–æ–¥–µ–ª—å
# model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
# for param in model.parameters():
#     param.requires_grad = False
# model.fc = nn.Linear(model.fc.in_features, len(classes))

# print(model.parameters())

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = model.to(device)

# criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

# # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
# losses = []
# y_true_all = []
# y_pred_all = []

# start_time = time.time()

# # –û–±—É—á–µ–Ω–∏–µ
# for epoch in range(EPOCHS):
#     model.train()
#     running_loss = 0

#     for images, labels in tqdm(dataloader, desc=f"–≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}"):
#         images, labels = images.to(device), labels.to(device)

#         optimizer.zero_grad()
#         outputs = model(images)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         running_loss += loss.item()

#         # –î–ª—è –º–µ—Ç—Ä–∏–∫
#         preds = torch.argmax(outputs, dim=1)
#         y_true_all.extend(labels.cpu().tolist())
#         y_pred_all.extend(preds.cpu().tolist())

#     epoch_loss = running_loss
#     losses.append(epoch_loss)
#     print(f"[{epoch+1}] Loss: {epoch_loss:.4f}")

# # –í—Ä–µ–º—è
# total_time = time.time() - start_time
# print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
# print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {round(total_time / 60, 2)} –º–∏–Ω—É—Ç")

# # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
# os.makedirs("models", exist_ok=True)
# torch.save(model.state_dict(), SAVE_PATH)
# print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤:", SAVE_PATH)

# # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥
# train_log = {
#     "losses": losses,
#     "training_time": total_time
# }
# with open(LOG_PATH, "w") as f:
#     json.dump(train_log, f)
# print("üìù –õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")

# # –°–æ—Ö—Ä–∞–Ω—è–µ–º confusion –¥–∞–Ω–Ω—ã–µ
# conf_data = {
#     "true": y_true_all,
#     "pred": y_pred_all
# }
# with open(CONFUSION_PATH, "w") as f:
#     json.dump(conf_data, f)
# print("üß© –î–∞–Ω–Ω—ã–µ –¥–ª—è confusion matrix —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")



import os
import time
import json
import torch
from torch import nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# –ü—É—Ç–∏
DATA_PATH = r"C:\Users\safar\OneDrive\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\elbrus\my_project_2_1\data\weather"
SAVE_PATH = "models/resnet_weather.pt"
LOG_PATH = "models/train_log.json"
CONFUSION_PATH = "models/confusion.json"
EPOCHS = 3
BATCH_SIZE = 16

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# –î–∞—Ç–∞—Å–µ—Ç –∏ DataLoader
dataset = datasets.ImageFolder(DATA_PATH, transform=transform)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ valid
train_size = int(0.8 * len(dataset))  # 80% –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
valid_size = len(dataset) - train_size  # 20% –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)

classes = dataset.classes
print("–ö–ª–∞—Å—Å—ã:", classes)

# –ú–æ–¥–µ–ª—å
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
for param in model.parameters():
    param.requires_grad = False
model.fc = nn.Linear(model.fc.in_features, len(classes))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
train_losses, valid_losses = [], []
train_accuracies, valid_accuracies = [], []

start_time = time.time()

# –û–±—É—á–µ–Ω–∏–µ
for epoch in range(EPOCHS):
    # Train
    model.train()
    running_loss = 0
    y_true_train, y_pred_train = [], []

    for images, labels in tqdm(train_loader, desc=f"Train –≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}"):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # –î–ª—è –º–µ—Ç—Ä–∏–∫
        preds = torch.argmax(outputs, dim=1)
        y_true_train.extend(labels.cpu().tolist())
        y_pred_train.extend(preds.cpu().tolist())

    train_loss = running_loss / len(train_loader)
    train_accuracy = accuracy_score(y_true_train, y_pred_train)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Validation
    model.eval()
    running_loss = 0
    y_true_valid, y_pred_valid = [], []

    with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        for images, labels in tqdm(valid_loader, desc=f"Valid –≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}"):
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            # –î–ª—è –º–µ—Ç—Ä–∏–∫
            preds = torch.argmax(outputs, dim=1)
            y_true_valid.extend(labels.cpu().tolist())
            y_pred_valid.extend(preds.cpu().tolist())

    valid_loss = running_loss / len(valid_loader)
    valid_accuracy = accuracy_score(y_true_valid, y_pred_valid)
    valid_losses.append(valid_loss)
    valid_accuracies.append(valid_accuracy)

    # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫
    print(f"[{epoch+1}] Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"[{epoch+1}] Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}")

# –í—Ä–µ–º—è
total_time = time.time() - start_time
print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {round(total_time / 60, 2)} –º–∏–Ω—É—Ç")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
os.makedirs("models", exist_ok=True)
torch.save(model.state_dict(), SAVE_PATH)
print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤:", SAVE_PATH)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥
train_log = {
    "train_losses": train_losses,
    "train_accuracies": train_accuracies,
    "valid_losses": valid_losses,
    "valid_accuracies": valid_accuracies,
    "training_time": total_time
}
with open(LOG_PATH, "w") as f:
    json.dump(train_log, f)
print("üìù –õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º confusion –¥–∞–Ω–Ω—ã–µ
conf_data = {
    "true": y_true_valid,
    "pred": y_pred_valid
}
with open(CONFUSION_PATH, "w") as f:
    json.dump(conf_data, f)
print("üß© –î–∞–Ω–Ω—ã–µ –¥–ª—è confusion matrix —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")