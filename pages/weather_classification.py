import streamlit as st
from PIL import Image
import torch
from torchvision import models, transforms
import time
import requests
from io import BytesIO
import os

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
MODEL_PATH = "models/resnet_weather.pt"
CLASS_NAMES = ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning',
               'rain', 'rainbow', 'rime', 'sandstorm', 'snow']

# --- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
@st.cache_resource
def load_model():
    model = models.resnet18(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(CLASS_NAMES))
    model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
    model.eval()
    return model

model = load_model()

# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.title("üå¶Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–∏–∫–æ–ª–æ–≤ –ø—Ä–∏—Ä–æ–¥—ã")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É ‚Äî –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç —Ç–∏–ø –ø–æ–≥–æ–¥–Ω–æ–≥–æ —è–≤–ª–µ–Ω–∏—è.")

uploaded_files = st.file_uploader("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
image_url = st.text_input("üîó –ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

images_to_classify = []

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏
if image_url:
    try:
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content)).convert("RGB")
        images_to_classify.append(("URL", image))
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {e}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
if uploaded_files:
    for file in uploaded_files:
        image = Image.open(file).convert("RGB")
        images_to_classify.append((file.name, image))

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
if images_to_classify:
    for name, image in images_to_classify:
        st.subheader(f"üñºÔ∏è {name}")
        st.image(image, width=300)

        input_tensor = transform(image).unsqueeze(0)

        with torch.no_grad():
            start = time.time()
            output = model(input_tensor)
            end = time.time()

        pred_class = CLASS_NAMES[output.argmax().item()]
        elapsed_time = end - start

        st.success(f"üåà –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: **{pred_class}**")
        st.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {elapsed_time:.3f} —Å–µ–∫")

else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É.")
